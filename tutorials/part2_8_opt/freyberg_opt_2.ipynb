{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When worlds collide: optimization under uncertainty\n",
    "\n",
    "In the previous optimization notebook (\"freyberg_opt_1.ipynb\"), we saw how we can use the PEST interface to also implement formal constrained management optimization.  And it was awesome!\n",
    "\n",
    "But what about all those other notebooks where we droned on and on about prediction uncertainty and parameter estimation/data assimilation?  Was that all for nothing?! \n",
    "\n",
    "No!  It wasn't.  In fact, in the same way that predictions are uncertain, constraints based on simulation results are also uncertain.  Let's take this a step further:  In many cases, the predictions we are focused on in our modeling have certain values that are important to decision makers.  We saw this in the previous optimization notebook:  future surface-water/groundwater exchange flux was a prediction in earlier notebooks, but was also used as a constraint to avoid an unwanted outcome (too little flux to sustain ecological flows).  So its only natural to think \"how can we combine the uncertainty analysis concepts with management optimization?\".  This is referrred to optimization under uncertainty and crux of the deal is the concept of \"chance constraints\".  \n",
    "\n",
    "Most optimization algorithms require that the constraint be assigned a single \"right-hand side\" value - the value not to violate.  But uncertainty analysis gives us a range (or statistical distribution) of possible constraint/prediction values.  How can we recitify this problem?  Well, if we realize that the statistical distribution covers the range of possible values that a given constraint may take (because of uncertainty), then that leads us to a concept of \"risk shifting\".  \"risk\" (aka reliability) is a simple scalar algorithmic control that ranges from 0.0 to 1.0.  A risk value of 0.5 is called \"risk neutral\" and it implies that 50% of the mass of a constraint probability density function is on either side of the value that corresponds to risk = 0.5 - think of the mean of a normal distribution:  at the mean value, half of the distribution is on either side.  A risk of 0.95 implies we want to be 95% sure the constraint will not be violated and is referred to as risk averse.  A risk averse stance implies we will have to accept a sub optimal objective function to be 95% sure.  The other side of the distribution is referred to as \"risk tolerant\" and it implies a decreasingly small chance that the constraint will actually be satisfied (danger zone!).  \n",
    "\n",
    "Why did we say \"actually be satisfied\" above?  Well, just like predictions, we dont know what the \"true\" or \"real world\" value of the model-based constraints is (if we did, we wouldnt need to be modeling at all!).  So we dont know what the \"true\" the constraint will take because its something we cant or haven't observed.  \n",
    "\n",
    "Ok, enough words.  Let's see how this works in practice.  Not that to run this notebook, you will have needed to run both the previous optimization notebook, as well as the PESTPP-IES part 1 notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Admin\n",
    "\n",
    "Start off with the usual loading of dependencies and preparing model and PEST files. We will be continuing to work with the modified-Freyberg model (see \"intro to model\" notebook), and the high-dimensional PEST dataset prepared in the \"pstfrom pest setup\" and \"obs and weights\" notebooks. \n",
    "\n",
    "For the purposes of this notebook, you do not require familiarity with previous notebooks (but it helps...). \n",
    "\n",
    "Simply run the next few cells by pressing `shift+enter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "font = {'family' : 'normal',\n",
    "        'size'   : 15}\n",
    "import matplotlib\n",
    "matplotlib.rc('font', **font)\n",
    "import matplotlib.pyplot as plt;\n",
    "import shutil\n",
    "import psutil\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,os.path.join(\"..\", \"..\", \"dependencies\"))\n",
    "import pyemu\n",
    "import flopy\n",
    "assert \"dependencies\" in flopy.__file__\n",
    "assert \"dependencies\" in pyemu.__file__\n",
    "sys.path.insert(0,\"..\")\n",
    "import herebedragons as hbd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To maintain continuity in the series of tutorials, we we use the PEST-dataset prepared in the \"obs and weigths\" tutorial. Run the next cell to copy fthe necessary files across. Note that if you will need to run the previous notebooks in the correct order beforehand.\n",
    "\n",
    "Specify the path to the PEST dataset template folder. Recall that we will prepare our PEST dataset files in this folder, keeping them separate from the original model files. Then copy across pre-prepared model and PEST files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the temporary working folder\n",
    "t_d = os.path.join('freyberg6_template_chance')\n",
    "if os.path.exists(t_d):\n",
    "    shutil.rmtree(t_d)\n",
    "\n",
    "org_t_d = os.path.join(\"freyberg6_template\")\n",
    "if not os.path.exists(org_t_d):\n",
    "    raise Exception(\"you need to run the '/part2_8_opt/freyberg_opt_1.ipynb' notebook\")\n",
    "\n",
    "shutil.copytree(org_t_d,t_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst_path = os.path.join(t_d, 'freyberg_mf6.pst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = pyemu.Pst(pst_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacks\n",
    "\n",
    "So mechanically, how do we come up with this constraint PDF?  We saw previously in the PESTPP-IES notebook that we had to run the posterior parameter ensemble to yield a predictive PDF.  Well its no different here:  We will grab that PESTPP-IES posterior parameter ensemble (and manipulate it a little to remove decision variables) and then identify that ensemble as a \"stack\" of parameter realizations that can be run thru the model to yield constraint PDFs.  Easy as!  \n",
    "\n",
    "Beware tho: including a stack in the optimization means we need to evaluate the stack at least once (see \"coupling\" below) which means we need queue up and run the stack along with the response matrix pertubation runs from before...lucky for you PESTPP-OPT does this automagically!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the pestpp-ies directory exists and that the posterior parameter ensemble exists\n",
    "ies_dir = os.path.join(\"..\",\"part2_6_ies\",\"master_ies_1\")\n",
    "if not os.path.exists(ies_dir):\n",
    "    raise Exception(\"you need to run the 'part2_6_ies/freyberg_ies_1_basics.ipynb' notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe_files = [f for f in os.listdir(ies_dir) if f.endswith(\".par.csv\") and f.startswith(\"freyberg_mf6\")]\n",
    "pe_files.sort()\n",
    "pe_files\n",
    "pe = pd.read_csv(os.path.join(ies_dir,pe_files[-1]),index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load the parameter ensemble from the last iteration of PESTPP-IES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = pd.read_csv(os.path.join(ies_dir,pe_files[-1]),index_col=0)\n",
    "pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par = pst.parameter_data\n",
    "par.loc[par.partrans==\"fixed\",\"partrans\"] = \"none\"\n",
    "wpar = par.loc[par.parnme.str.contains(\"wel\") & par.parnme.str.contains(\"cn\"),\"parnme\"]\n",
    "pe.loc[:,wpar.values] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe.to_csv(os.path.join(t_d,\"par_stack.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.pestpp_options[\"opt_par_stack\"] = \"par_stack.csv\"\n",
    "pst.pestpp_options[\"opt_risk\"] = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_org = pst.observation_data.copy()\n",
    "obs = pst.observation_data\n",
    "#obs.loc[obs.apply(lambda x: x.weight > 0 and \"wel\" in x.obsnme,axis=1),\"weight\"] = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.noptmax = 1\n",
    "pst.write(pst_path,version=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An aside on \"coupling\": interaction between decision variables, parameters, and constraints\n",
    "\n",
    "blahblahblah\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Attention!\n",
    "\n",
    "You must specify the number which is adequate for ***your*** machine! Make sure to assign an appropriate value for the following `num_workers` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 15 #psutil.cpu_count(logical=False) # update according to your available resources!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then specify the folder in which the PEST manager will run and record outcomes. It should be different from the `t_d` folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_d = os.path.join('master_opt_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell deploys the PEST agents and manager and then starts the run using `pestpp-opt`. Run it by pressing `shift+enter`.\n",
    "\n",
    "If you wish to see the outputs in real-time, switch over to the terminal window (the one which you used to launch the `jupyter notebook`). There you should see `pestpp-opt`'s progress. \n",
    "\n",
    "If you open the tutorial folder, you should also see a bunch of new folders there named `worker_0`, `worker_1`, etc. These are the agent folders. `pyemu` will remove them when PEST finishes running.\n",
    "\n",
    "This run should take a while to complete (depending on the number of workers and the speed of your machine). If you get an error, make sure that your firewall or antivirus software is not blocking `pestpp-opt` from communicating with the agents (this is a common problem!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemu.os_utils.start_workers(t_d,\"pestpp-opt\",\"freyberg_mf6.pst\",num_workers=num_workers,worker_root=\".\",\n",
    "                           master_dir=m_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing PESTPP-OPT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = obs_org.loc[obs_org.weight > 0,:].copy()\n",
    "wel_constraint_names = obs.loc[obs.obsnme.str.contains(\"inc\") & obs.obsnme.str.contains(\"wel\"),\"obsnme\"]\n",
    "swgw_constraint_names = obs.loc[obs.obsnme.str.contains(\"inc\") & obs.obsnme.str.contains(\"sfr\"),\"obsnme\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[f for f in os.listdir(m_d) if f.endswith(\".rei\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we also have \"chance\" files, which, as the name implies, are residual files that represent the estimated and simulated observation quantities with the chance/risk offsets included.  Let's compare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swgw_rhs = obs.loc[swgw_constraint_names,\"obsval\"].max()\n",
    "wel_rhs = obs.loc[wel_constraint_names,\"obsval\"].max()\n",
    "chance_df = pyemu.pst_utils.read_resfile(os.path.join(m_d,\"freyberg_mf6.1.est+chance.rei\"))\n",
    "est_df = pyemu.pst_utils.read_resfile(os.path.join(m_d,\"freyberg_mf6.1.est.rei\"))\n",
    "constraints = swgw_constraint_names.tolist()\n",
    "constraints.extend(wel_constraint_names)\n",
    "fig,ax = plt.subplots(1,1,figsize=(10,3))\n",
    "est_df.loc[swgw_constraint_names,\"chance+estimated\"] = chance_df.loc[swgw_constraint_names,\"modelled\"]\n",
    "est_df.loc[:,\"estimated\"] = est_df.modelled.values\n",
    "est_df.loc[swgw_constraint_names,[\"estimated\",\"chance+estimated\"]].plot(ax=ax,kind=\"bar\")\n",
    "ax.plot(ax.get_xlim(),[swgw_rhs,swgw_rhs],\"k--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here we see the cost of uncertainty:  we have to leave a large amount groundwater in the system so that be can be sure (at 95% confidence) that the sw-gw flux will 0.0 or negative (the orange bars are right at 0.0 for most stress periods, showing the precision of the optimization solver)\n",
    "\n",
    "Now let's tie it all together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpar = par.loc[par.pargp==\"decvars\",:]\n",
    "future_wpar_names = wpar.parnme\n",
    "par_df = pyemu.pst_utils.read_parfile(os.path.join(m_d,\"freyberg_mf6.par\"))\n",
    "par_df.loc[future_wpar_names,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpar = wpar.loc[future_wpar_names,:].copy()\n",
    "wpar.loc[:,\"kij\"] = wpar.apply(lambda x: (x.idx0,x.idx1,x.idx2),axis=1)\n",
    "wpar.loc[:,\"optimal\"] = par_df.loc[wpar.parnme,\"parval1\"]\n",
    "wpar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_vals = wpar.inst.unique()\n",
    "inst_vals.sort()\n",
    "inst_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"r\",\"g\",\"b\",\"c\",\"m\",\"y\",\"0.5\"]\n",
    "vals = {}\n",
    "for inst in inst_vals:\n",
    "    ipar = wpar.loc[wpar.inst==inst,:].copy()\n",
    "    ipar.sort_values(by=\"kij\",inplace=True)\n",
    "    ipar.index = ipar.kij\n",
    "    #ipar.optimal.plot(ax=ax,kind=\"bar\",color=colors)\n",
    "    vals[inst] = ipar.optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig,axes = plt.subplots(2,1,figsize=(20,20))\n",
    "colors = [\"r\",\"g\",\"b\",\"c\",\"m\",\"y\",\"0.5\"]\n",
    "df = pd.DataFrame(vals).T\n",
    "df.plot(ax=axes[0],kind=\"bar\",color=colors)\n",
    "axes[0].set_ylim(0,9)\n",
    "nconst = len(wel_constraint_names)-1\n",
    "axes[1].plot(np.arange(nconst),est_df.loc[wel_constraint_names,\"modelled\"].values[1:],\"b\",lw=1.5)\n",
    "axes[1].plot(axes[1].get_xlim(),[wel_rhs,wel_rhs],\"b--\",lw=3.5)\n",
    "axes[1].fill_between(np.arange(nconst),np.zeros(nconst) + wel_rhs,\n",
    "                     est_df.loc[wel_constraint_names,\"modelled\"].values[1:],facecolor=\"b\",alpha=0.5)\n",
    "axt = plt.twinx(axes[1])\n",
    "axt.plot(np.arange(nconst),est_df.loc[swgw_constraint_names,\"modelled\"].values[1:],\"m\",lw=1.5)\n",
    "axt.fill_between(np.arange(nconst),np.zeros(nconst) + swgw_rhs,\n",
    "                     est_df.loc[swgw_constraint_names,\"modelled\"].values[1:],facecolor=\"m\",alpha=0.5)\n",
    "axes[1].set_xticklabels(inst_vals)\n",
    "axes[0].set_xlim(0,12)\n",
    "axes[1].set_xticks(np.arange(len(wel_constraint_names)-1))\n",
    "axes[1].set_xlim(0,12)\n",
    "axt.plot(axes[1].get_xlim(),[swgw_rhs,swgw_rhs],\"m--\",lw=3.5)\n",
    "axes[1].set_ylim(-10000,0)\n",
    "axt.set_ylim(-700,800)\n",
    "axes[0].set_title(\"Decision Variables\",loc=\"left\")\n",
    "axes[1].set_title(\"Constraints\",loc=\"left\")\n",
    "[i.set_color(\"b\") for i in axes[1].get_yticklabels()]\n",
    "[i.set_color(\"m\") for i in axt.get_yticklabels()]\n",
    "lb = axes[1].set_ylabel(\"groundwater extraction rate\")\n",
    "lb.set_color('b')\n",
    "lb = axt.set_ylabel(\"sw-gw exchange rate\")\n",
    "lb.set_color('m')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we see the cost of uncertainty: we are pumping much less water compared to the risk-neutral case so that we can leave that groundwater to discharge to the surface-water system.  #reliability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reusing previous results \n",
    "\n",
    "\n",
    "If we can rely on those estimated values from the solver, we can do some trickery to skip any additional model runs while we explore the additional problem formulations.  This means we can change the constrain right-hand sides and risk....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.copy2(os.path.join(m_d,\"freyberg_mf6.1.jcb\"),os.path.join(m_d,\"restart.jcb\"))\n",
    "pst.pestpp_options[\"base_jacobian\"] = \"restart.jcb\"\n",
    "shutil.copy2(os.path.join(m_d,\"freyberg_mf6.1.jcb.rei\"),os.path.join(m_d,\"restart.res\"))\n",
    "pst.pestpp_options[\"hotstart_resfile\"] = \"restart.res\"\n",
    "shutil.copy2(os.path.join(m_d,\"freyberg_mf6.1.obs_stack.csv\"),os.path.join(m_d,\"obs_stack.csv\"))\n",
    "pst.pestpp_options[\"opt_obs_stack\"] = \"obs_stack.csv\"\n",
    "pst.pestpp_options.pop(\"opt_par_stack\",None)\n",
    "pst.pestpp_options[\"opt_skip_final\"] = True\n",
    "\n",
    "pst.write(os.path.join(m_d,\"freyberg_mf6_restart.pst\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemu.os_utils.run(\"pestpp-opt freyberg_mf6_restart.pst\",cwd=m_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do something fun:  sweep over a full range of risk values and see how the objective function changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_rec():\n",
    "    with open(os.path.join(m_d,\"freyberg_mf6_restart.rec\"),'r') as f:\n",
    "        for line in f:\n",
    "            if \"---  best objective function value:\" in line:\n",
    "                print(line)\n",
    "                obj_val = float(line.strip().split()[-1])\n",
    "                break\n",
    "    return obj_val\n",
    "\n",
    "obj_vals = []\n",
    "cwname = \"oname:cum_otype:lst_usecol:wel_totim:4383.5\"\n",
    "cw_vals = []\n",
    "pst.observation_data.loc[cwname,\"obgnme\"] = \"less_than\"\n",
    "pst.observation_data.loc[cwname,\"obsval\"] = 1.0e+10\n",
    "pst.observation_data.loc[cwname,\"weight\"] = 1.0\n",
    "\n",
    "\n",
    "risk_vals = np.linspace(0.001,0.999,100)\n",
    "for risk_val in risk_vals:\n",
    "    pst.pestpp_options[\"opt_risk\"] = risk_val\n",
    "    pst.write(os.path.join(m_d,\"freyberg_mf6_restart.pst\"))\n",
    "    pyemu.os_utils.run(\"pestpp-opt freyberg_mf6_restart.pst\",cwd=m_d)\n",
    "    obj_vals.append(scrape_rec())\n",
    "    df = pyemu.pst_utils.read_resfile(os.path.join(m_d,\"freyberg_mf6_restart.1.est.rei\"))\n",
    "    cw_vals.append(df.loc[cwname,\"modelled\"])\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(10,10))\n",
    "ax.plot(risk_vals,obj_vals)\n",
    "ax.grid()\n",
    "ax.set_xlabel(\"risk\")\n",
    "ax.set_ylabel(\"objective function\")\n",
    "ax.set_xticks(np.arange(0,1.1,0.1))\n",
    "axt = plt.twinx(ax)\n",
    "axt.plot(risk_vals,np.array(cw_vals)*-1,alpha=0.0)\n",
    "axt.set_ylabel(\"cumulative groundwater extracted ($L^3$)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that is a million dollar plot!  We are seeing the optimal solution to the constrained groundwater management problem across varying risk stances. And we can assign cost of uncertainty in terms of volume of extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
