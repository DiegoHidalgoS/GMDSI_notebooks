{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to management optimization (under uncertainty)\n",
    "\n",
    "So far in these awesome tutorial notebooks, we have been focused on estimating uncertain model inputs (i.e. parameters), estimating the uncertainty in these inputs, and propagating the unceratinty in these inputs to important model outputs (i.e. predictions), namely unmeasured groundwater levels and surface-water/groundwater exchange fluxes during (unseen) dry conditions.  Now we are going to go the next level and start to use the model in an entirely new way:  rather than estimating the uncertainty in important model outputs during unseen dry conditions, what if we \"flip the script\" and instead ask the question \"how much groundwater can we extract before the surface-water/groundwater exchange flux reaches an unacceptable value\"?  And what if we augment the question with something even more exciting: \"...at the 95% confidence level\"?  OOOhhh that sounds so nice!  \n",
    "\n",
    "Let's begin our journey with some terminology:\n",
    "\n",
    "    - \"parameter\": an uncertain model input whose value we want to estimate and whose uncertainty we want to propagate to important model outputs\n",
    "    - \"decision variable\": a model input whose value can be \"controlled\" by human activity.  For example, groundwater extraction rates or surface-water structure opertions.  Like a parameter, a decision variable also influences important model outputs.\n",
    "    - \"constraint\": an uncertain model output whose real-world equivalent value has a range of \"undesired values\".  In management optimization, \"constraints\" are typically \"inequality\" constraints, meaning the constraint can take any value other than the undesired values.  Think \"surface-water/groundwater exchange flux must be greater than XXX to support ecological flows\".\n",
    "    - \"chance constraint\": given that the relation between decision variables and constraints must be evaluated with the model, constraints are \"uncertain\" in exactly the same way the \"predictions\" or \"forecasts\" are uncertain. Therefore, it only makes sense that we include \"uncertainty\" in the management optimization process.  One way to do this is with \"chance constraints\", where we include uncertainty in the constraints.  However, most management optimization algorithms do not tolerate a statistical distribution of constraint values - they need a single value.  So we will use the concept of \"risk\" to identify a scalar constraint value from the statistical constraint distribution - a scalar value that implicitly represents the underlying uncertainty.\n",
    "    - \"risk\": a value that ranges for 0.0 (risk tolerant) to 1.0 (risk averse). When you see \"risk\" think \"reliabiliy\". The more risk averse you are, the more \"uncertainty\" will cost you in the final optimization solution.\n",
    "    - \"objective function\": a (potentially nonlinear) function of the decision variables that is to be maximized or minimized, depending on the problem.  For example, in the case of groundwater extraction, the objective is to maximize the volume of groundwater extracted (subject to not violating the constraints).\n",
    "    \n",
    "\n",
    "Whew!  Ok, lets see some of this in practice...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Admin\n",
    "\n",
    "Start off with the usual loading of dependencies and preparing model and PEST files. We will be continuing to work with the modified-Freyberg model (see \"intro to model\" notebook), and the high-dimensional PEST dataset prepared in the \"pstfrom pest setup\" and \"obs and weights\" notebooks. \n",
    "\n",
    "For the purposes of this notebook, you do not require familiarity with previous notebooks (but it helps...). \n",
    "\n",
    "Simply run the next few cells by pressing `shift+enter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt;\n",
    "import shutil\n",
    "import psutil\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,os.path.join(\"..\", \"..\", \"dependencies\"))\n",
    "import pyemu\n",
    "import flopy\n",
    "assert \"dependencies\" in flopy.__file__\n",
    "assert \"dependencies\" in pyemu.__file__\n",
    "sys.path.insert(0,\"..\")\n",
    "import herebedragons as hbd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To maintain continuity in the series of tutorials, we we use the PEST-dataset prepared in the \"obs and weigths\" tutorial. Run the next cell to copy fthe necessary files across. Note that if you will need to run the previous notebooks in the correct order beforehand.\n",
    "\n",
    "Specify the path to the PEST dataset template folder. Recall that we will prepare our PEST dataset files in this folder, keeping them separate from the original model files. Then copy across pre-prepared model and PEST files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the temporary working folder\n",
    "t_d = os.path.join('freyberg6_template')\n",
    "if os.path.exists(t_d):\n",
    "    shutil.rmtree(t_d)\n",
    "\n",
    "org_t_d = os.path.join(\"..\",\"part2_2_obs_and_weights\",\"freyberg6_template\")\n",
    "if not os.path.exists(org_t_d):\n",
    "    raise Exception(\"you need to run the '/part2_2_obs_and_weights/freyberg_obs_and_weights.ipynb' notebook\")\n",
    "\n",
    "shutil.copytree(org_t_d,t_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst_path = os.path.join(t_d, 'freyberg_mf6.pst')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the PEST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK. We can now get started.\n",
    "\n",
    "Load the PEST control file as a `Pst` object. We are going to use the PEST control file that was created in the \"pstfrom pest setup\" tutorial. This control file has observations with weights equal to the inverse of measurement noise (**not** weighted for visibility!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = pyemu.Pst(pst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see if obs&weights notebook has been run\n",
    "if not pst.observation_data.observed.sum()>0:\n",
    "    raise Exception(\"You need to run the '/part2_2_obs_and_weights/freyberg_obs_and_weights.ipynb' notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a quick parameter summary table as a reminder of what we have in our control file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.write_par_summary_table(filename=\"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that our parameterisation is quite comprehensive, with pilot points and grid based (e.g. cell-by-cell) parameters. \n",
    "\n",
    "Let's recall how many adjustable parameters we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.npar_adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving from DA/UQ to OPT: decision variables\n",
    "\n",
    "As previously discussed, we are now moving away from the data assimilation and uncertainty analysis focus to one of management optimization.  Fortunately for you, we have been planning this journey all along and have included all the nessecary pieces for management optimization with in the PEST interface we have been using - wat?!  How can this be?! Well, for starters, we have been estimating uncertain historical and future groundwater extraction rates (the `WEL` package \"flux\" quantities). While it is obvs important to account for this important source of model input uncertainty, these same \"parameters\" can also be recast as \"decision varibles\" - they are one in the same, depending on the analysis you are interested in...\n",
    "\n",
    "Let's examine these important model inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par = pst.parameter_data\n",
    "wpar = par.loc[par.parnme.str.contains(\"welgrd\"),:]\n",
    "wpar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the \"grid-scale\" well flux parameters are just the thing we are wanting to use as decision variables.  But - and this is important - we want to only optimize future water use subject to future surface-water/groundwater exchange constraints.  This means we want to only treat \"future\" water use as decision variables, where \"future\" refers to stress periods 13 thru 25 (remember all that from the previous notebooks?).  So we want to fix all \"parameters\" except the grid-scale well flux parameters for stress periods 13 thru 25.  The `inst` metadata gives us a zero-based stress period tag (lucky us!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpar.loc[:,\"inst\"] = wpar.inst.astype(int)\n",
    "par.loc[:,\"partrans\"] = \"fixed\"\n",
    "future_wpar_names = wpar.loc[wpar.inst >= 13,\"parnme\"]\n",
    "future_wpar_names.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to do some trickery to help us use these \"parameters\" as decision variables, mostly related to the bounds and transform; we want to be able to \"turn off\" a given extraction well, so we want its transform to be `none` and we want it's lower bound to 0.0 (remember these are actually multiplier parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par.loc[future_wpar_names,\"partrans\"] = \"none\"\n",
    "par.loc[future_wpar_names,\"parlbnd\"] = 0.0\n",
    "par.loc[future_wpar_names,\"parval1\"] = 0.0\n",
    "par.loc[future_wpar_names,\"parubnd\"] = 6.0\n",
    "par.loc[future_wpar_names,\"pargp\"] = \"decvars\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to set just one little \"++\" arg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.pestpp_options[\"opt_dec_var_groups\"] = \"decvars\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving from DA/UQ to OPT: decision variables: objective function\n",
    "\n",
    "Its an unfortunately naming issue but the \"objective function\" we have talked about for many, many notebooks will now mean something completely different.  As a quick aside, its important to realize that the reason we talk about the \"objective function\" in the previous notebooks and thru out the PEST world is because all of the PEST and PEST++ tools for parameter estimation/data assimilation/uncertainty quantification are in fact optimization algorithms that have been repurposed for these analyses.  But, unlike before, where we had to worry about overfitting, parameter plausibility, etc, we are now free to adjust decision variables in any pattern we like and we are free to seek the absolute best objective function value.  \n",
    "\n",
    "So what should our objective function be?!  Well, our management objective is to maximize extracted groundwater.  So the objective function is a simple sum of the decision variable values - easy as!  So how does this look in the PEST interface?  Answer:  prior information equation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.add_pi_equation(future_wpar_names,pilbl=\"obj_well\",obs_group=\"greater_than\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.prior_information.equation[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yikes!  that looks like a bunch of junk but really its a simple equation summing all of the future water use decision variable values.  The right-hand side value of 0.0 is unused; we tagged this prior info equation with a \"greater_than\" tag for two reasons:  0) to remind us what we want maximize this value and 1) for later, more advanced optimization analyses.  For now, to use the most basic optimization tool in pest++, we will pass the objective direction directly to the algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.pestpp_options[\"opt_direction\"] = \"max\"\n",
    "pst.pestpp_options[\"opt_objective_function\"] = \"obj_well\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving from DA/UQ to OPT: decision variables: objective function\n",
    "\n",
    "This is where things get interesting.  If we were to run the optimization now, the algorithm would simply take each decision variable to its upper bound since that is the maximum of the objective function.  But this would obvs not be acceptable because of ecological impacts (the surface-water/grounwater exchange would be not-good!)  So we need to \"constrain\" the optimization problem.  \n",
    "\n",
    "A bit more terminology: a \"feasible\" solution is one where the decision variables yield a simulation result that satisfies all of the constraints.  \n",
    "\n",
    "Let's now setup \"model-based\" or observation constraints.  We are going to target the \"incremental\" global water budget SFR components - these represent the flux of groundwater to surface-water.  Note the sign convention is negative means from groundwater to surface-water.  So to maintain ecological flows, we want to keep a (substantially) negative value.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = pst.observation_data\n",
    "swgw_obs = obs.loc[obs.obsnme.str.contains(\"inc\") & obs.obsnme.str.contains(\"sfr\"),:]\n",
    "swgw_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swgw_obs.obsval.plot(figsize=(15,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that in stress periods 13 thru 25, the incremental surface flux gets pretty close to 0.0, the point where groundwater stops contributing to surface-water.  So lets form an interesting optimization problem:  the incremental SFR flux must be \"less than\" -100 $\\frac{L^3}{T}$.  We tell the PEST++ optmization tools about these constraints by tagging their observation group name with \"less_than\" and giving them non-zero weight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swgw_obs.loc[:,\"totim\"] = swgw_obs.totim.astype(float)\n",
    "swgw_constraint_names = swgw_obs.loc[swgw_obs.totim > 4000,\"obsnme\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.loc[:,\"weight\"] = 0.0 #deactivate all existing non-zero weighted observations\n",
    "obs.loc[swgw_constraint_names,\"weight\"] = 1.0 # just non-zero, the value doesnt matter...\n",
    "obs.loc[swgw_constraint_names,\"obsval\"] = -250.0 # the constraint right hand side\n",
    "\n",
    "obs.loc[swgw_constraint_names,\"obgnme\"] = \"less_than_swgw\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! but there is another problem:  what if there is a minimum flux of groundwater that is needed?  So for municipal use?  This optimization problem will just turn groundwater extraction rates way down during the dry season to meet ecological constraints, but that might not be enough drinking water - the classic competition for resources problem.  Let's add some more constraints to make sure a minimum amount of groundwater is also produced.  We can do this using the incremental WEL budget component or we can add additional prior information equations, one for each future stress period.  Its probably easiest to just use the incremental budget obs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wel_obs = obs.loc[obs.obsnme.str.contains(\"inc\") & obs.obsnme.str.contains(\"wel\"),:]\n",
    "wel_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see an observed value of -2350.0 during the future stress periods so let's go with half of that, assuming that number is meaningful (?).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wel_obs.loc[:,\"totim\"] = wel_obs.totim.astype(float)\n",
    "wel_constraint_names = wel_obs.loc[wel_obs.totim>4000,\"obsnme\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.loc[wel_constraint_names,\"weight\"] = 1.0\n",
    "obs.loc[wel_constraint_names,\"obgnme\"] = \"less_than_wel\" #again, negative means out of groundwater\n",
    "obs.loc[wel_constraint_names,\"obsval\"] = -2350.0 #again, negative means out of groundwater\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run PESTPP-OPT\n",
    "\n",
    "`PESTPP-OPT` implements a sequential linear programming algorithm.  The linear programming solve is done using the simplex algorithm (not the Nelder-Meade simplex, the Danzig simplex).  This algorithm requires a \"response\" matrix - a matrix the maps the linear relation between decision variables and constraints.  Sound familiar?  Its exactly the same concept as the jacobian matrix and we will again rely on finite difference derivatives to fill this matrix - one model run per decision variable.  But, unlike a jacobian used for parameter estimation/data assimilation, we want to make sure the decision variable pertubation is large enough that we have a representative response at the constraints. So to do this, we will use some of the derivative calculation controls in the `* parameter groups` section:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.rectify_pgroups()\n",
    "pst.parameter_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.parameter_groups.loc[\"decvars\",\"inctyp\"] = \"absolute\"\n",
    "pst.parameter_groups.loc[\"decvars\",\"derinc\"] = 1.0 #remember these are multipliers!\n",
    "pst.parameter_groups.loc[\"decvars\",\"derinclb\"] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.control_data.noptmax = 0\n",
    "pst.write(pst_path,version=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemu.os_utils.run(\"pestpp-opt freyberg_mf6.pst\",cwd=t_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.control_data.noptmax = 1\n",
    "pst.write(pst_path,version=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention!\n",
    "\n",
    "You must specify the number which is adequate for ***your*** machine! Make sure to assign an appropriate value for the following `num_workers` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 15 #psutil.cpu_count(logical=False) # update according to your available resources!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then specify the folder in which the PEST manager will run and record outcomes. It should be different from the `t_d` folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_d = os.path.join('master_opt_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell deploys the PEST agents and manager and then starts the run using `pestpp-opt`. Run it by pressing `shift+enter`.\n",
    "\n",
    "If you wish to see the outputs in real-time, switch over to the terminal window (the one which you used to launch the `jupyter notebook`). There you should see `pestpp-opt`'s progress. \n",
    "\n",
    "If you open the tutorial folder, you should also see a bunch of new folders there named `worker_0`, `worker_1`, etc. These are the agent folders. `pyemu` will remove them when PEST finishes running.\n",
    "\n",
    "This run should take a while to complete (depending on the number of workers and the speed of your machine). If you get an error, make sure that your firewall or antivirus software is not blocking `pestpp-opt` from communicating with the agents (this is a common problem!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemu.os_utils.start_workers(t_d,\"pestpp-opt\",\"freyberg_mf6.pst\",num_workers=num_workers,worker_root=\".\",\n",
    "                           master_dir=m_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing PESTPP-OPT\n",
    "\n",
    "Ok, so now what? Well let's check out the constraints (since the include both the water use and sw-gw exchange fluxes).  Here are the files that might have what we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[f for f in os.listdir(m_d) if f.endswith(\".rei\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wat?! Whats with this \"est\" and \"sim\" stuff?  Well, in PESTPP-OPT, the linear-programming solution yields what it thinks the final constraint values should be, based on the assumed linearity of the response matrix - these are the \"est\"imated constraint values.  But we know that the relation between decision variables and constraints might be non-linear (nah, really?!).  So PESTPP-OPT actually \"sim\"ulates the model one last time with the optimal decision variable values to verify the results. (the \".jcb.rei\" files are the simulation results where the response matrix was calculated).  Lets compare these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df = pyemu.pst_utils.read_resfile(os.path.join(m_d,\"freyberg_mf6.1.est.rei\"))\n",
    "est_df = pyemu.pst_utils.read_resfile(os.path.join(m_d,\"freyberg_mf6.1.sim.rei\"))\n",
    "constraints = swgw_constraint_names.tolist()\n",
    "constraints.extend(wel_constraint_names)\n",
    "fig,ax = plt.subplots(1,1,figsize=(10,3))\n",
    "sim_df.loc[swgw_constraint_names,\"est\"] = est_df.loc[swgw_constraint_names,\"modelled\"]\n",
    "sim_df.loc[swgw_constraint_names,[\"modelled\",\"est\"]].plot(ax=ax,kind=\"bar\")\n",
    "ax.plot(ax.get_xlim(),[-250,-250],\"k--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so we see that there is some mild nonlinearity but we are still pretty close.  #winning\n",
    "\n",
    "Hackery alert:  now lets visualize the pattern of groundwater use across the future stress periods and plot that with the constraint information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_df = pyemu.pst_utils.read_parfile(os.path.join(m_d,\"freyberg_mf6.par\"))\n",
    "par_df.loc[future_wpar_names,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpar = wpar.loc[future_wpar_names,:].copy()\n",
    "wpar.loc[:,\"kij\"] = wpar.apply(lambda x: (x.idx0,x.idx1,x.idx2),axis=1)\n",
    "wpar.loc[:,\"optimal\"] = par_df.loc[wpar.parnme,\"parval1\"]\n",
    "wpar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_vals = wpar.inst.unique()\n",
    "inst_vals.sort()\n",
    "inst_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(1,len(inst_vals),figsize=(15,3))\n",
    "colors = [\"r\",\"g\",\"b\",\"c\",\"m\",\"y\",\"0.5\"]\n",
    "for inst,ax in zip(inst_vals,axes):\n",
    "    ipar = wpar.loc[wpar.inst==inst,:].copy()\n",
    "    ipar.sort_values(by=\"kij\",inplace=True)\n",
    "    ipar.index = ipar.kij\n",
    "    ipar.optimal.plot(ax=ax,kind=\"bar\",color=colors)\n",
    "    ax.set_title(\"stress period {0}\".format(inst+1),loc=\"left\")\n",
    "    ax.set_ylabel(\"extraction factor\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cobs = obs.loc[constraints,:].copy()\n",
    "cobs.loc[:,\"totim\"] = cobs.totim.astype(float)\n",
    "totims = cobs.totim.unique()\n",
    "totims.sort()\n",
    "#print(cobs.totim)\n",
    "fig, axes = plt.subplots(2,1,figsize=(15,3))\n",
    "axes[0].plot(cobs.loc[swgw_constraint_names,\"totim\"].values,sim_df.loc[swgw_constraint_names,\"modelled\"].values)\n",
    "axes[0].plot(cobs.loc[swgw_constraint_names,\"totim\"].values,cobs.loc[swgw_constraint_names,\"obsval\"].values)\n",
    "\n",
    "axes[0].set_ylim(-500,0)\n",
    "axes[0].plot(axes[0].get_xlim(),[-250,-250],\"k--\")\n",
    "axes[1].plot(cobs.loc[wel_constraint_names,\"totim\"].values,sim_df.loc[wel_constraint_names,\"modelled\"].values)\n",
    "axes[1].plot(axes[1].get_xlim(),[-2350,-2350],\"k--\")\n",
    "axes[1].set_ylim(-8000,0)\n",
    "axes[0].set_xticks(totims)\n",
    "axes[1].set_xticks(totims)\n",
    "axes[0].set_xlim(totims[0],totims[-1])\n",
    "axes[1].set_xlim(totims[0],totims[-1])\n",
    "axes[0].set_title(\"sw-gw constraints\",loc=\"left\")\n",
    "axes[1].set_title(\"wel constraints\",loc=\"left\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
